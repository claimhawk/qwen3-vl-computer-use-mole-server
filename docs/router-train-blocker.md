# Router Training Blocker (Qwen3-VL) - RESOLVED

## Status: FIXED (2024-11-24)

All blockers have been resolved. Training and evaluation now work end-to-end.

## Issues Fixed

### 1. Hidden Size AttributeError (Original Blocker)
**Error:** `AttributeError: 'Qwen3VLConfig' object has no attribute 'hidden_size'`

**Solution:** Added `get_hidden_size(model)` helper that correctly extracts the hidden dimension:
- Checks `model.config.hidden_size` (standard transformers)
- Falls back to `model.model.config.hidden_size` (Qwen3-VL's inner LM config) âœ“
- Falls back to `model.config.text_config.hidden_size` (some VLM patterns)
- Falls back to inspecting `model.model.embed_tokens.weight.shape[1]`

### 2. CUDA Out of Memory
**Error:** `torch.OutOfMemoryError: CUDA out of memory` on A10G (22GB)

**Solution:** Load encoder with bfloat16 and device_map:
```python
encoder = Qwen3VLForConditionalGeneration.from_pretrained(
    base_model_id,
    trust_remote_code=True,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)
```

### 3. Dtype Mismatch
**Error:** `RuntimeError: mat1 and mat2 must have the same dtype, but got BFloat16 and Float`

**Solution:** Cast router head to bfloat16 to match encoder outputs:
```python
self.head.to(device=device, dtype=torch.bfloat16)
```

### 4. Missing `last_hidden_state` Attribute
**Error:** `AttributeError: 'Qwen3VLCausalLMOutputWithPast' object has no attribute 'last_hidden_state'`

**Solution:** Use `output_hidden_states=True` and access `hidden_states[-1]`:
```python
outputs = encoder(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)
hidden = outputs.hidden_states[-1][:, 0, :]  # First token of last layer
```

## Validation Results (1 Epoch Test)

Training completed successfully:
```
Epoch 1: loss=2.4166
Saved router head to /output/router-head.pt
```

Evaluation completed:
```
Eval metrics: {
  'accuracy': 0.3667,
  'total': 5454,
  'correct': 2000,
  'confusion': {
    'calendar->provider-select': 3054,
    'claim-window->provider-select': 400,
    'provider-select->provider-select': 2000
  }
}
```

Note: Low accuracy with 1 epoch is expected. The model currently defaults to `provider-select` for all inputs. Train with more epochs (`--epochs 5` or higher) to improve routing accuracy.

## What works
- Routing data includes calendar, claim-window, provider-select adapters and is uploaded to Modal:
  - `claimhawk-training-data:/routing/routing-train.jsonl`
  - `claimhawk-training-data:/routing/routing-eval.jsonl`
  - Local copies: `data/routing-train.jsonl`, `data/routing-eval.jsonl`.
- LoRAs are in `moe-lora-checkpoints`:
  - `/checkpoints/calendar-tasks`
  - `/checkpoints/claim-window`
  - `/checkpoints/provider-select`
- Router code (`modal/router_train.py`) mounts the above, auto-detects adapters, supports eval mode, and uses the Qwen3 trainer stack:
  - Image: torch 2.4.0, torchvision 0.19.0, flash-attn 2.8.3 wheel, transformers >=4.57.0, accelerate>=0.27.0, peft>=0.11.0, qwen-vl-utils, numpy<2.
  - Model loading: `Qwen3VLForConditionalGeneration.from_pretrained(..., trust_remote_code=True)`.

## Original Failure (now fixed)
- Modal train run crashed when initializing the router head:
  ```
  AttributeError: 'Qwen3VLConfig' object has no attribute 'hidden_size'
  ```
  at `self.head = RouterHead(self.encoder.config.hidden_size, num_labels)`.

## Technical Details
- Qwen3VLConfig wraps multiple sub-configs (vision, text/LLM)
- The text encoder hidden dimension is at `model.model.config.hidden_size`
- The pooled text feature for classification uses `hidden_states[-1][:,0,:]` (first token of last layer)
- No additional package versions required beyond the existing stack

## Modal command (for reference)
```
uvx modal run modal/router_train.py::run \
  --mode train \
  --data-path /data/routing/routing-train.jsonl \
  --base-model-id Qwen/Qwen3-VL-8B-Instruct \
  --router-out /output/router-head.pt \
  --lora-calendar /checkpoints/calendar-tasks \
  --lora-claim /checkpoints/claim-window \
  --lora-provider /checkpoints/provider-select \
  --epochs 1 --batch-size 8
```
